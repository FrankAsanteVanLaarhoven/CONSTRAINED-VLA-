{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 12: Train VLA Policy with Llama 3.1\n",
    "\n",
    "This notebook demonstrates how to train a **Vision-Language-Action (VLA)** model using **Llama 3.1** as the reasoning backbone.\n",
    "We fine-tune the model to map (Observation + Instruction) -> (Safe Navigation Action).\n",
    "\n",
    "**Architecture**:\n",
    "- **Base Model**: Llama-3.1-8B-Instruct (4-bit Quantized for Colab T4).\n",
    "- **Input**: \"<image_embedding> Context: You are a safe robot in a hospital. Goal: [18, 10]. Nearest Obstacle: Person at 1.5m.\"\n",
    "- **Output**: \"Action: Forward 0.3 Turn 0.1\"\n",
    "\n",
    "**Dataset**: Generated `dataset_v0.1` (Hospital Benchmark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab Setup\n",
    "!pip install -q transformers accelerate bitsandbytes peft datasets pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Add src to path\n",
    "try:\n",
    "    sys.path.append(os.path.abspath('../src'))\n",
    "except:\n",
    "    pass # Colab path might differ\n",
    "\n",
    "DATASET_DIR = \"../data/dataset_v0.1\"\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3.1-8B-Instruct\" # Requires HuggingFace Login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data for Llama\n",
    "Convert CSV trajectories into Instruction Tuning format.\n",
    "Format: `User: <State Description> \\n Assistant: <Action>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(row, goal, nearest_dist):\n",
    "    # Simple text representation of state\n",
    "    # ideally we would use the image (Grid Map) + Projection\n",
    "    # For V0.1 we use text description of state\n",
    "    prompt = f\"\"\"Control a robot in a hospital.\n",
    "State: x={row['x']:.2f}, y={row['y']:.2f}, theta={row['theta']:.2f}.\n",
    "Goal: x={goal[0]:.2f}, y={goal[1]:.2f}.\n",
    "Sensors: Nearest obstacle at {nearest_dist:.2f}m.\n",
    "Output the linear and angular velocity safely.\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def format_output(row):\n",
    "    return f\"Action: v_lin={row['v_lin']:.2f}, v_ang={row['v_ang']:.2f}\"\n",
    "\n",
    "train_samples = []\n",
    "\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    worlds = os.listdir(DATASET_DIR)\n",
    "    for w in worlds[:5]: # load subset\n",
    "        w_path = os.path.join(DATASET_DIR, w)\n",
    "        if not os.path.isdir(w_path): continue\n",
    "        \n",
    "        ep_dir = os.path.join(w_path, \"episodes\")\n",
    "        if not os.path.exists(ep_dir): continue\n",
    "        \n",
    "        for ep in os.listdir(ep_dir):\n",
    "            if not ep.endswith(\"_log.csv\"): continue\n",
    "            df = pd.read_csv(os.path.join(ep_dir, ep))\n",
    "            # Sample 10% of frames to reduce size\n",
    "            df_sub = df.iloc[::10]\n",
    "            \n",
    "            for _, row in df_sub.iterrows():\n",
    "                # Mock nearest dist (would calculate real)\n",
    "                d_mock = 2.0 \n",
    "                prompt = format_instruction(row, (18, 10), d_mock)\n",
    "                completion = format_output(row)\n",
    "                train_samples.append({\"text\": f\"User: {prompt}\\nAssistant: {completion}\"})\n",
    "                \n",
    "print(f\"Prepared {len(train_samples)} training samples.\")\n",
    "print(\"Example:\", train_samples[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model (Quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In Colab, you need to login to HF first using notebook_login()\n",
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# Placeholder for actual loading - Uncomment in Colab\n",
    "# model = AutoModelForCausalLM.from_pretrained(MODEL_ID, quantization_config=bnb_config, device_map=\"auto\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "# tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LoRA Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# print(\"Model ready for training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
