{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 07: Baseline Summary & Analysis\n",
    "\n",
    "This notebook analyzes the **Safety-Transfer Hospital Benchmark v0.1 Dataset**.\n",
    "It computes the final aggregate metrics for the baseline policy (Mock / Nav2).\n",
    "\n",
    "**Metrics Reported:**\n",
    "- **Safety Violation Rate (SVR)**: Mean % time in Red Zones.\n",
    "- **Task Success Rate (TSR)**: % of episodes reaching goal (Mock: always 1.0 if not stuck).\n",
    "- **Near-Violation Time (NVT)**: Mean time in Amber Zones.\n",
    "- **Minimum Distances**: Distribution of closest approaches to Beds/People."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from metrics.safety_evaluator import SafetyEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "Iterate through `data/dataset_v0.1` and process every episode log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../data/dataset_v0.1\"\n",
    "results = []\n",
    "\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "    print(f\"Dataset directory {DATASET_DIR} not found. Run Notebook 06 first.\")\n",
    "else:\n",
    "    # Walk through worlds\n",
    "    worlds = sorted([d for d in os.listdir(DATASET_DIR) if d.startswith(\"world_\")])\n",
    "    \n",
    "    print(f\"Found {len(worlds)} worlds to analyze.\")\n",
    "    \n",
    "    for w_name in worlds:\n",
    "        w_path = os.path.join(DATASET_DIR, w_name)\n",
    "        \n",
    "        # Load World Config\n",
    "        with open(os.path.join(w_path, \"objects.json\"), 'r') as f:\n",
    "            world_config = json.load(f)\n",
    "        \n",
    "        evaluator = SafetyEvaluator(world_config['objects'])\n",
    "        \n",
    "        # Process Episodes\n",
    "        ep_dir = os.path.join(w_path, \"episodes\")\n",
    "        if not os.path.exists(ep_dir): continue\n",
    "            \n",
    "        episodes = sorted([f for f in os.listdir(ep_dir) if f.endswith(\"_log.csv\")])\n",
    "        \n",
    "        for ep_file in episodes:\n",
    "            log_path = os.path.join(ep_dir, ep_file)\n",
    "            log_df = pd.read_csv(log_path)\n",
    "            \n",
    "            if len(log_df) == 0: continue\n",
    "                \n",
    "            metrics, _ = evaluator.evaluate_episode(log_df)\n",
    "            \n",
    "            metrics['World'] = w_name\n",
    "            metrics['Episode'] = ep_file\n",
    "            results.append(metrics)\n",
    "\n",
    "    df_res = pd.DataFrame(results)\n",
    "    print(f\"Processed {len(df_res)} episodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aggregate Statistics\n",
    "Compute the benchmark table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_res.empty:\n",
    "    print(\"=== Benchmark v0.1 Summary ===\")\n",
    "    print(df_res[['SVR', 'Red_Steps', 'Amber_Moving_Steps', 'Min_Dist_Person', 'Min_Dist_Bed']].describe())\n",
    "    \n",
    "    mean_svr = df_res['SVR'].mean()\n",
    "    std_svr = df_res['SVR'].std()\n",
    "    print(f\"\\nMean SVR: {mean_svr*100:.2f}% Â± {std_svr*100:.2f}%\")\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizations\n",
    "\n",
    "### 3.1 SVR Distribution\n",
    "How safe is the baseline policy? (Expect high SVR for unconstrained baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_res.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df_res['SVR'], kde=True, bins=20)\n",
    "    plt.title(\"Distribution of Safety Violation Rate (SVR)\")\n",
    "    plt.xlabel(\"SVR (Fraction of time in Red Zone)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Minimum Distance Analysis\n",
    "How close does the robot get to critical objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_res.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df_res[['Min_Dist_Person', 'Min_Dist_Bed']])\n",
    "    plt.title(\"Minimum Distance to Objects\")\n",
    "    plt.ylabel(\"Distance (m)\")\n",
    "    \n",
    "    # Add thresholds for reference (Person Crit)\n",
    "    plt.axhline(y=0.5, color='r', linestyle='--', label='Person Crit (0.5m)')\n",
    "    plt.axhline(y=0.4, color='b', linestyle='--', label='Bed Crit (0.4m)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    # Log scale might be useful if outliers are far, but linear is fine for safety zones\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
